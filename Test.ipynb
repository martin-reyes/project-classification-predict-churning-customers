{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca329fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "451d7232",
   "metadata": {},
   "source": [
    "**1. Readme (.md)**\n",
    "\n",
    "- [x] project description with goals\n",
    "- [x] initial hypotheses and/or questions you have of the data, ideas\n",
    "- [x] data dictionary\n",
    "- [x] project planning (lay out your process through the data science pipeline)\n",
    "- [x] instructions or an explanation of how someone else can reproduce your project and findings (What would someone need to be able to recreate your project on their own?)\n",
    "- [x] key findings, recommendations, and takeaways from your project\n",
    "\n",
    "**2. Final Report (.ipynb)**\n",
    "\n",
    "- [ ] A Report that has filtered out all the extraneous elements not necessary to include in the report.\n",
    "- [ ] Use markdown throughout the notebook to guide the audience. Assume the reader will not read your code blocks as you think about how much markdown guidance do you need.\n",
    "- [x] Then, assume another reader will read ALL of your code, so make sure it is very very clearly commented. All cells with code need comments.\n",
    "- [x] Your notebook should begin with a project overview and goals\n",
    "- [x] Preparation should specifically call out any ways you changed the data (like handling nulls)\n",
    "- [x] Provide the context of the target variable through a visualization (distribution of the values, e.g.)\n",
    "- [x] Exploration should be refined in the report because now you know which visualizations and tests led to valuable outcomes.\n",
    "- [x] Include at least 4 visualizations in the form of:\n",
    "    - Question in markdown that you want to answer\n",
    "    - Visualization\n",
    "    - Statistical test (in at least 2 of your 4)\n",
    "    - Provide your clear answer or takeaway in markdown and natural language to the question based on your exploration\n",
    "- [ ] Include your 3 best models in the final notebook to review. Show the steps and code you went through to fit the models, evaluate, and select.\n",
    "- [ ] On your best model, a chart visualizing how it performed on test would be valuable.\n",
    "- [x] End with a conclusion that talks about your original goals and how you reached those (or didn't), the key findings, recommendations and next steps (\"If I had more time, I would...\")\n",
    "\n",
    "**3.Acquire & Prepare Modules (.py)**\n",
    "\n",
    "- [x] contains functions to acquire, prepare and split your data. You can have other .py files if you desire to abstract other code away from your final report.\n",
    "- [x] Your work must be reproducible by someone with their own env.py file.\n",
    "- [x] Each of your functions are complimented with docstrings. If they are functions you borrowed from instructors, put those docstrings in your own words.\n",
    "- [x] Functions to acquire and prepare your data should be imported and used in your final report.\n",
    "\n",
    "**4. Predictions (.csv)**\n",
    "- [x] 3 columns: customer_id, probability of churn, and prediction of churn. (1=churn, 0=not_churn).\n",
    "- [x] These predictions should be from your best performing model ran on X_test.\n",
    "- [x] Note that the order of the y_pred and y_proba are numpy arrays coming from running the model on X_test. The order of those values will match the order of the rows in X_test, so you can obtain the customer_id from X_test and concatenate these values together into a dataframe to write to CSV.\n",
    "\n",
    "**5. non-final Notebook(s) (.ipynb)**\n",
    "- [x] there should be at least 1 non-final notebook\n",
    "- [x] these were created while working on the project, containing exploration & modeling work (and other work), not shown in the final report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e805cd18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ebaee9d3",
   "metadata": {},
   "source": [
    "# README"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acdb3f8f",
   "metadata": {},
   "source": [
    "<a name=\"top\"></a>\n",
    "\n",
    "# Why Are Customers Churning\n",
    "\n",
    "by Martin Reyes\n",
    "\n",
    "<!-- <p>\n",
    "  <a href=\"https://github.com/martin-reyes\" target=\"_blank\">\n",
    "<img src=\"https://cdn-icons-png.flaticon.com/128/3291/3291695.png\" alt=\"GitHub\" width=\"40\" height=\"40\">\n",
    "  </a>\n",
    "\n",
    "  <a href=\"https://www.linkedin.com/in/martin-reyes-ds/\" target=\"_blank\">\n",
    "<img src=\"https://cdn-icons-png.flaticon.com/128/3536/3536505.png\" alt=\"LinkedIn\" width=\"40\" height=\"40\">\n",
    "    </a>\n",
    "</p>\n",
    " -->\n",
    "\n",
    "## Project Description\n",
    "\n",
    "23% of current customers on record have churned. In this project, we will aim to find drivers in customer churn by  exploring data acquired on our MySQL database. We will explore features both individually and relative to customer churn status. We will take these insights, present them, and use them to create machine learning models to predict whether a customer churns. After evaluating the models with metrics that address our goals, we will use the models to come up with recommendations and predictions on churningn customers.\n",
    "\n",
    " \n",
    "## Project Goal\n",
    " \n",
    "* Discover drivers of customers churning and other key insights.\n",
    "* Use main drivers to develop a machine learning model to predict churning customers.\n",
    "* Use insights and model evaluation to identify features to address when a customer is predicted to churn.\n",
    "\n",
    " \n",
    "## Initial Thoughts\n",
    " \n",
    "My initial hypothesis is our demographic features, gender and senior citizen status, will not relate to churn while our numerical features (tenure, monthly charges, and total charges) will.\n",
    " \n",
    "## The Plan\n",
    " \n",
    "* **Acquire** data from MYSQL\n",
    " \n",
    "* **Prepare** data. \n",
    "    1. Inspect raw data and note any desired transformations which may include any of the following:\n",
    "        * Drop unnecessary columns (duplicate, redundant columns)\n",
    "        * Numeric columns should be numeric data types\n",
    "        * Handle missing values and impute appropriate values\n",
    "            * check for explicit missing values (e.g. `np.nan`)\n",
    "            * check for implicit missing values (e.g. whitespace, `'unknown'`, etc.)\n",
    "        * Deal with any duplicate rows\n",
    "        * Address and encode categorical columns\n",
    "            * one-hot encode unordered categorical columns\n",
    "            * label encode ordered categorical columns  \n",
    "    1. Inspect clean data\n",
    "        * Ensure data is tidy:\n",
    "            * one value per cell\n",
    "            * each observation is one and only one row\n",
    "            * each feature is one and only one column\n",
    "    1. Split the data\n",
    "        * Determine if target column has class imbalance. If, so stratify.\n",
    "        * We will do 70/15/15 train/validate/test split.\n",
    "        * **RANDOM_STATE will be 125**\n",
    "    1. Create data dictionary\n",
    "    1. Summarize data transformations\n",
    "\n",
    "* **Explore** data in search of features that drive churn\n",
    "   1. General Inspect\n",
    "       - `.info()` and `.describe()`\n",
    "       - identify continuous and categorical columns\n",
    "   1. Univariate Stats: \n",
    "       - Categorical\n",
    "       - Nunerical\n",
    "   1. Bivariate Stats:\n",
    "       - Categorical features to target relationships\n",
    "       - Continuous features to target relationship\n",
    "   1. Use these quick insights to ask and answer specific questions:\n",
    "       - Which features appear to relate to churn the most?\n",
    "      \n",
    "* Develop a **model** to predict if a customer will churn\n",
    "   * Use drivers identified in explore to build predictive models of different types\n",
    "   * Create and run a baseline model with `sklearn`'s `DummyClassifier` to compare our results to\n",
    "   * Create and run KNN, Logistic Regression, and Decistion Tree classification models\n",
    "   * Use the insights from the highest-performing model (with highest test accuracy) to confirm our initial hypotheses and insights on the features that are the biggest drivers of churn\n",
    "   \n",
    "* **Evaluate** models on train and validate data\n",
    "   * Identify the metric to maximize\n",
    "       * Do we simply want an accurate model?\n",
    "       * If not is it more costly to incorrectly identify non-churning customers (FN) or churning customers (FP)?\n",
    "   * Select the best model based on highest desired metric\n",
    "\n",
    "* Evaluate the best model on validation data set. After we find the best model, test on the test set.\n",
    "    * Save test predictions to a csv file\n",
    " \n",
    "* Draw conclusions\n",
    " \n",
    " \n",
    "<a name=\"data-dictionary\"></a>\n",
    "## Data Dictionary\n",
    "\n",
    "| Feature              | Definition |\n",
    "|:----------------------|:-------------------- |\n",
    "| customer_id          | Unique identifier for each customer |\n",
    "| gender_male          | Indicates whether the customer is male or not |\n",
    "| senior_citizen       | Indicates whether the customer is a senior citizen or not |\n",
    "| partner              | Indicates whether the customer has a partner or not |\n",
    "| dependents           | Indicates whether the customer has dependents or not |\n",
    "| tenure               | Number of months the customer has been with the company |\n",
    "| phone_service        | Indicates whether the customer has phone service or not |\n",
    "| multiple_lines       | Indicates whether the customer has multiple lines for phone |\n",
    "| online_security      | Indicates whether the customer has online security service or not |\n",
    "| online_backup        | Indicates whether the customer has online backup service or not |\n",
    "| device_protection | Indicates whether the customer has device protection service or not|\n",
    "| tech_support         | Indicates whether the customer has tech support service or not|\n",
    "| streaming_tv         | Indicates whether the customer has streaming TV service or not|\n",
    "| streaming_movies   | Indicates whether the customer has streaming movies service or not|\n",
    "| paperless_billing  | Indicates whether the customer has opted for paperless billing or not|\n",
    "| monthly_charges      | The amount charged to the customer on a monthly basis |\n",
    "| total_charges        | The total amount charged to the customer over the entire tenure |\n",
    "| churn (**target**)      | Indicates whether the customer has churned (cancelled the service) or not |\n",
    "| contract_type   | The type of contract the customer has (e.g., month-to-month, one-year, two-year)|\n",
    "| internet_service_type| The type of internet service the customer has (e.g., DSL, fiber optic, None) |\n",
    "| payment_type      | The method of payment used by the customer (e.g., electronic check, credit card, bank transfer, mailed check) |\n",
    "|Additional Features|Encoded and values for categorical data|\n",
    "\n",
    " \n",
    "## Steps to Reproduce\n",
    "1. Clone this repo.\n",
    "2. To acquire data, ensure env.py file is in local repo with MySQL credentials, or [telco_churn_raw.csv](data/telco_churn_raw.csv) is in the data folder.\n",
    "3. Run through notebooks to produce results.\n",
    " \n",
    "## Summary\n",
    "Key Insights:\n",
    "- Strong Drivers of Churn:\n",
    "    - Tenure\n",
    "        - Churners have a shorter tenure\n",
    "    - Internet Service Type\n",
    "        - Churners largely have fiber optic internet\n",
    "    - Contract Type\n",
    "        - Churners are largely on month-to-month contracts\n",
    "        - Churners are rarely on twy-year contracts\n",
    "    - Payment by Electronic Check\n",
    "        - Churners typically pay by electronic check\n",
    "        \n",
    "We were able to outperform our baseline accuracy of 73% by fitting a logistic regression classifier and getting an 80.5% accuracy.\n",
    "\n",
    "\n",
    "## Recommendations\n",
    "* With most churning customers leaving in the first few months, we should take action early to prevent churn.\n",
    "    * We can take low-cost actions like reaching out and offering a survey of customer satisfaction.\n",
    "    * We can consider higher-investment actions like offering promotions or early discounts\n",
    "* Take similar action to encourage customers to go on a one or two year contract rather than month-to-month.\n",
    "* We should see why those with fiber-optic cable churn more than others.\n",
    "    * Is this cost related? (look into monthly charges) \n",
    "    * How does out fiber-optic cable perform?\n",
    "\n",
    "## Next Steps\n",
    "With more time, we can:\n",
    "- Do Multivariate analysis and see how a combination or columns relate to churn \n",
    "- Develop a better-performing model by feature engineering, feature scaling, running other ML classifiers, etc.\n",
    "- If we want to take action with any of the recommendations, we can change our performance metric to precision or recall, and predict and target customers this way.\n",
    "\n",
    "[Back to top](#top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ef2286",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
